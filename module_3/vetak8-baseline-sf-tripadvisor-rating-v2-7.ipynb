{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.pata.org/wp-content/uploads/2014/09/TripAdvisor_Logo-300x119.png)\n",
    "# Predict TripAdvisor Rating\n",
    "## В этом соревновании нам предстоит предсказать рейтинг ресторана в TripAdvisor\n",
    "**По ходу задачи:**\n",
    "* Прокачаем работу с pandas\n",
    "* Научимся работать с Kaggle Notebooks\n",
    "* Поймем как делать предобработку различных данных\n",
    "* Научимся работать с пропущенными данными (Nan)\n",
    "* Познакомимся с различными видами кодирования признаков\n",
    "* Немного попробуем [Feature Engineering](https://ru.wikipedia.org/wiki/Конструирование_признаков) (генерировать новые признаки)\n",
    "* И совсем немного затронем ML\n",
    "* И многое другое...   \n",
    "\n",
    "\n",
    "\n",
    "### И самое важное, все это вы сможете сделать самостоятельно!\n",
    "\n",
    "*Этот Ноутбук являетсся Примером/Шаблоном к этому соревнованию (Baseline) и не служит готовым решением!*   \n",
    "Вы можете использовать его как основу для построения своего решения.\n",
    "\n",
    "> что такое baseline решение, зачем оно нужно и почему предоставлять baseline к соревнованию стало важным стандартом на kaggle и других площадках.   \n",
    "**baseline** создается больше как шаблон, где можно посмотреть как происходит обращение с входящими данными и что нужно получить на выходе. При этом МЛ начинка может быть достаточно простой, просто для примера. Это помогает быстрее приступить к самому МЛ, а не тратить ценное время на чисто инженерные задачи. \n",
    "Также baseline являеться хорошей опорной точкой по метрике. Если твое решение хуже baseline - ты явно делаешь что-то не то и стоит попробовать другой путь) \n",
    "\n",
    "В контексте нашего соревнования baseline идет с небольшими примерами того, что можно делать с данными, и с инструкцией, что делать дальше, чтобы улучшить результат.  Вообще готовым решением это сложно назвать, так как используются всего 2 самых простых признака (а остальные исключаются)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "\n",
    "# Загружаем специальный удобный инструмент для разделения датасета:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geonamescache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import geonamescache\n",
    "gc = geonamescache.GeonamesCache()\n",
    "\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\n",
    "# df_train = pd.read_csv(DATA_DIR+'/main_task.csv')\n",
    "# df_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\n",
    "# sample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')\n",
    "df_train = pd.read_csv('main_task.csv')\n",
    "df_test = pd.read_csv('kaggle_task.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\n",
    "df_train['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0 # помечаем где у нас тест\n",
    "df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "df = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее по признакам:\n",
    "* City: Город \n",
    "* Cuisine Style: Кухня\n",
    "* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n",
    "* Price Range: Цены в ресторане в 3 категориях\n",
    "* Number of Reviews: Количество отзывов\n",
    "* Reviews: 2 последних отзыва и даты этих отзывов\n",
    "* URL_TA: страница ресторана на 'www.tripadvisor.com' \n",
    "* ID_TA: ID ресторана в TripAdvisor\n",
    "* Rating: Рейтинг ресторана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Reviews[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, большинство признаков у нас требует очистки и предварительной обработки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Prepping Data\n",
    "Обычно данные содержат в себе кучу мусора, который необходимо почистить, для того чтобы привести их в приемлемый формат. Чистка данных — это необходимый этап решения почти любой реальной задачи.   \n",
    "![](https://analyticsindiamag.com/wp-content/uploads/2018/01/data-cleaning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Обработка признаков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().plot(kind='bar',title='Количество пропусков')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Признаки Cuisine Style, Price Range, Number of Reviews  содержат много пропусков.\n",
    "# Заполним их и создадим новые признаки,\"is_NAN\" , которые будут говорить о наличии пропуска)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cuisine Style_NAN'] = df['Cuisine Style'].isna().astype('uint8')\n",
    "df['Price Range_NAN'] = df['Price Range'].isna().astype('uint8')\n",
    "df['Number of Reviews_NAN'] = df['Number of Reviews'].isna().astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Restaurant_id**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,['Restaurant_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Признак не содержит полезной информации, удалим его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Restaurant_id'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_population(city):\n",
    "    total_info = gc.get_cities_by_name(city)\n",
    "    if total_info != []:\n",
    "        total_info = gc.get_cities_by_name(city)[0]\n",
    "        city_code = next(iter(total_info.keys()))\n",
    "        population = total_info[city_code]['population']\n",
    "        return population\n",
    "\n",
    "    else:\n",
    "        if city == 'Oporto':\n",
    "            population = 214349\n",
    "        elif city == 'Zurich':\n",
    "            population = 402762\n",
    "        elif city == 'Krakow':\n",
    "            population = 779115\n",
    "        return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = {\n",
    "    'Paris': 'France',\n",
    "    'Hamburg': 'Germany',\n",
    "    'Rome': 'Italy',\n",
    "    'London': 'UK',\n",
    "    'Milan': 'Italy',\n",
    "    'Madrid': 'Spain',\n",
    "    'Oslo': 'Norway',\n",
    "    'Stockholm': 'Sweden',\n",
    "    'Krakow': 'Poland',\n",
    "    'Lyon': 'Paris',\n",
    "    'Lisbon': 'Portugal',\n",
    "    'Edinburgh': 'UK',\n",
    "    'Vienna': 'Austria',\n",
    "    'Warsaw': 'Poland',\n",
    "    'Amsterdam': 'Netherlands',\n",
    "    'Budapest': 'Hungary',\n",
    "    'Helsinki': 'Finland',\n",
    "    'Zurich': 'Switzerland',\n",
    "    'Luxembourg': 'Luxembourg',\n",
    "    'Berlin': 'Germany',\n",
    "    'Prague': 'Czechia',\n",
    "    'Munich': 'Germany',\n",
    "    'Bratislava': 'Slovakia',\n",
    "    'Brussels': 'Belgium',\n",
    "    'Ljubljana': 'Slovenia',\n",
    "    'Copenhagen': 'Denmark',\n",
    "    'Oporto': 'Portugal',\n",
    "    'Barcelona': 'Spain',\n",
    "    'Geneva': 'Switzerland',\n",
    "    'Athens': 'Greece',\n",
    "    'Dublin': 'Ireland'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "df.City.value_counts().plot(kind='bar', title='Количество ресторанов в городах')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_count = dict(df['City'].value_counts())\n",
    "df['rest_count'] = df['City'].map(city_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['population'] = df['City'].apply(lambda x: get_population(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'] = df['City'].map(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rest_per_people'] = df['rest_count'] / df['population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_list = ['London', 'Paris', 'Stockholm', 'Madrid', 'Berlin',\n",
    "                'Rome', 'Prague', 'Lisbon', 'Vienna', 'Amsterdam', \n",
    "                'Budapest', 'Warsaw', 'Dublin', 'Copenhagen',\n",
    "                'Athens', 'Edinburgh', 'Oslo', 'Helsinki', \n",
    "                'Bratislava', 'Ljubljana', 'Brussels', 'Luxembourg']\n",
    "\n",
    "df['is_capital'] = df['City'].apply(lambda x: 1 if x in capital_list else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод \n",
    "### На практике признаки \"столица или нет\" и \"отношение кол-ва ресторанов к кол-ву людей в городе\" результат не дали. В итоговом решении учтены не будут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuisine Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем кол-во редких кухонь\n",
    "def get_rare_cuisines_count(cuis):\n",
    "    x = 0\n",
    "    for i in rare_cuisins_list:\n",
    "        if i in cuis:\n",
    "            x += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем кол-во часто встречающихся кухонь\n",
    "def get_common_cuisines_count(cuis):\n",
    "    x = 0\n",
    "    for i in common_cuisins_list:\n",
    "        if i in cuis:\n",
    "            x += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_ones(x):\n",
    "    if cus in x:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_rare(cuis):\n",
    "    for i in cuis:\n",
    "        if i in rare_cuisins_list:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    \n",
    "    \n",
    "def is_common(cuis):\n",
    "    for i in cuis:\n",
    "        if i in common_cuisins_list:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполняем пустые значения \"Other\"\n",
    "df['Cuisine Style'].fillna(\"['Other']\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем строчные значения в списки\n",
    "df['Cuisine Style'] = df['Cuisine Style'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество кухонь в ресторане\n",
    "df['count_cuisines'] = df['Cuisine Style'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "pd.Series.explode(df['Cuisine Style']).value_counts().plot(\n",
    "    kind='bar', title='Колличество встреч кухонь по видам')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим два признака \"is_rare\", \"rare_cuisines_count\" со значениями 1 и 0 в первом, в зависимости от того, есть ли среди кухонь ресторана редкие или часто встречающиеся, и с количеством редких кухонь во втором. За критерий редкости возьмем медиальное значение этого параметра."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Взорвали столбец \"Cuisine Style\"\n",
    "exploded_cuisin_list = pd.Series.explode(df['Cuisine Style']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список кухонь, количество встреч которых, мы наблюдаем реже чем медиальное значение общего количества встреч кухонь.\n",
    "rare_cuisins_list = exploded_cuisin_list.loc[exploded_cuisin_list < round(\n",
    "    exploded_cuisin_list.median())].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список кухонь, количество встреч которых, мы наблюдаем чаще чем медиальное значение общего количества встреч кухонь.\n",
    "common_cuisins_list = exploded_cuisin_list.loc[exploded_cuisin_list > round(\n",
    "    exploded_cuisin_list.median())].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rare_cuisines_count'] = df['Cuisine Style'].apply(get_rare_cuisines_count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Признаки с часто встречающимися кухнями результат не дали\n",
    "# df['common_cuisines_count'] = df['Cuisine Style'].apply(get_common_cuisines_count)\n",
    "# df['is_common'] = df['Cuisine Style'].apply(is_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_rare'] = df['Cuisine Style'].apply(is_rare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisines = pd.Series.explode(df['Cuisine Style']).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15,6)\n",
    "df.Ranking.hist(bins=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price Range'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_dict = {'$': 1,\n",
    "              '$$ - $$$': 2,\n",
    "              '$$$$': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price Range'] = df['Price Range'].map(price_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Заполним пропуски наиболее часто встречающимся значением 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price Range'].fillna(2, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number of Reviews'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number of Reviews'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number of Reviews'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Столбец строковый, содержит информацию с отзывами и датами отзывов. Много незаполненных значений формата \"[[], []]\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(s: 'str'):\n",
    "    fin = []\n",
    "    tmp = re.findall('\\d\\d/\\d\\d/\\d{4}', s)\n",
    "    if [] not in tmp:\n",
    "        for i in tmp:\n",
    "            dt_tmp = datetime.strptime(i, '%m/%d/%Y')\n",
    "            fin.append(dt_tmp)\n",
    "\n",
    "        return fin\n",
    "    else:\n",
    "        return [0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_date(x):    \n",
    "    if len(x) > 1:\n",
    "        return abs((x[0]-x[1]).days)\n",
    "    else:\n",
    "        return abs((x[0]-x[0]).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Reviews'].fillna('[[], []]',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_review'] = df['Reviews'].apply(lambda x: get_date(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Найдем дату первого отзыва по всем ресторанам и заполним ей пустые значения\n",
    "dates = []\n",
    "for i in df.date_review:\n",
    "    if i != None:\n",
    "        for j in i:\n",
    "            dates.append(j)\n",
    "min_date = min(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_review'] = df['date_review'].apply(lambda x: [min_date,min_date] if x ==[] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_review'].apply(lambda x: [min_date,min_date] if x ==[] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Берем первый элемент из списка дат в каждой строке, \n",
    "# так как он соответствует более позднему комментарию\n",
    "df['last_review_date'] = df['date_review'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Берем первый элемент из списка дат в каждой строке, \n",
    "# если количество дат отзывов меньше двух. Иначе второй,так как может быть 3 даты отзывов\n",
    "df['prelast_review_date'] = df['date_review'].apply(\n",
    "    lambda x: x[0] if len(x) < 2 else x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признак с количеством дней между последними отзывами \"delta_date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delta_date'] = df['date_review'].apply(lambda x: get_delta_date(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delta_date'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признак с количеством дней между последним оставленным отзывом и сегодняшней датой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.now()\n",
    "df['delta_current_date'] = df['last_review_date'].apply(lambda x: (today - x).days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA \n",
    "[Exploratory Data Analysis](https://ru.wikipedia.org/wiki/Разведочный_анализ_данных) - Анализ данных\n",
    "На этом этапе мы строим графики, ищем закономерности, аномалии, выбросы или связи между признаками.\n",
    "В общем цель этого этапа понять, что эти данные могут нам дать и как признаки могут быть взаимосвязаны между собой.\n",
    "Понимание изначальных признаков позволит сгенерировать новые, более сильные и, тем самым, сделать нашу модель лучше.\n",
    "![](https://miro.medium.com/max/2598/1*RXdMb7Uk6mGqWqPguHULaQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим распределение признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10,7)\n",
    "df_train['Ranking'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас много ресторанов, которые не дотягивают и до 2500 места в своем городе, а что там по городам?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['City'].value_counts(ascending=True).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А кто-то говорил, что французы любят поесть=) Посмотрим, как изменится распределение в большом городе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Ranking'][df_train['City'] =='London'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на топ 10 городов\n",
    "for x in (df_train['City'].value_counts())[0:10].index:\n",
    "    df_train['Ranking'][df_train['City'] == x].hist(bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что Ranking имеет нормальное распределение, просто в больших городах больше ресторанов, из-за мы этого имеем смещение.\n",
    "\n",
    ">Подумайте как из этого можно сделать признак для вашей модели. Я покажу вам пример, как визуализация помогает находить взаимосвязи. А далее действуйте без подсказок =) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим распределение целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Rating'].value_counts(ascending=True).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим распределение целевой переменной относительно признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Ranking'][df_train['Rating'] == 5].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Ranking'][df_train['Rating'] < 4].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### И один из моих любимых - [корреляция признаков](https://ru.wikipedia.org/wiki/Корреляция)\n",
    "На этом графике уже сейчас вы сможете заметить, как признаки связаны между собой и с целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15,10)\n",
    "sns.heatmap(df.drop(['sample'], axis=1).corr(),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Изучив таблицу коррелиции признаков, убираем сильно коррелириющие признаки \"is_common\", \"common_cuisines_count\", "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще благодаря визуализации в этом датасете можно узнать много интересных фактов, например:\n",
    "* где больше Пицерий в Мадриде или Лондоне?\n",
    "* в каком городе кухня ресторанов более разнообразна?\n",
    "\n",
    "придумайте свои вопрос и найдите на него ответ в данных)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummies\n",
    "### Добавим Dummies в конце, для удобства отслеживания эффективности добавленных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_city = df.City.str.get_dummies()\n",
    "df = pd.concat([df,dummy_city],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cus in cuisines:\n",
    "    df[cus] = df['Cuisine Style'].apply(fill_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Теперь, для удобства и воспроизводимости кода, завернем всю обработку в одну большую функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# на всякий случай, заново подгружаем данные\n",
    "df_train = pd.read_csv('main_task.csv')\n",
    "df_test = pd.read_csv('kaggle_task.csv')\n",
    "df_train['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0 # помечаем где у нас тест\n",
    "df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_data(df_input):\n",
    "    '''includes several functions to pre-process the predictor data.'''\n",
    "\n",
    "    df_output = df_input.copy()\n",
    "\n",
    "    # ################### 0. Функции ##############################################################\n",
    "    # Получаем информацию из сторонней библиотеки\n",
    "    def get_population(city):\n",
    "        total_info = gc.get_cities_by_name(city)\n",
    "        if total_info != []:\n",
    "            total_info = gc.get_cities_by_name(city)[0]\n",
    "            city_code = next(iter(total_info.keys()))\n",
    "            population = total_info[city_code]['population']\n",
    "            return population\n",
    "        else:\n",
    "            if city == 'Oporto':\n",
    "                population = 214349\n",
    "            elif city == 'Zurich':\n",
    "                population = 402762\n",
    "            elif city == 'Krakow':\n",
    "                population = 779115\n",
    "            return population\n",
    "\n",
    "    # Получаем кол-во редких кухонь\n",
    "    def get_rare_cuisines_count(cuis):\n",
    "        x = 0\n",
    "        for i in rare_cuisins_list:\n",
    "            if i in cuis:\n",
    "                x += 1\n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "    # Функция энкодинга кухонь\n",
    "    def fill_ones(x):\n",
    "        if cus in x:\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Функция присваивающая 1, если кухня среди редких, иначе- 0\n",
    "    def is_rare(cuis):\n",
    "        for i in cuis:\n",
    "            if i in rare_cuisins_list:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "            \n",
    "            \n",
    "\n",
    "    # Получаем дату из отзывов\n",
    "    def get_date(s: 'str'):\n",
    "        fin = []\n",
    "        tmp = re.findall('\\d\\d/\\d\\d/\\d{4}', s)\n",
    "        if [] not in tmp:\n",
    "            for i in tmp:\n",
    "                dt_tmp = datetime.strptime(i, '%m/%d/%Y')\n",
    "                fin.append(dt_tmp)\n",
    "            return fin\n",
    "        else:\n",
    "            return [0, 0]\n",
    "\n",
    "    # Получаем разницу между отзывами в днях\n",
    "    def get_delta_date(x):\n",
    "        if len(x) > 1:\n",
    "            return abs((x[0]-x[1]).days)\n",
    "        else:\n",
    "            return abs((x[0]-x[0]).days)\n",
    "        \n",
    "        \n",
    "    # Полярность отзыва\n",
    "    def polarity_rev(x):\n",
    "        if '[]' not in x:\n",
    "            text = x\n",
    "            sent = TextBlob(text)\n",
    "            polarity = sent.sentiment.polarity\n",
    "            return polarity\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # ################### 1. Предобработка ##############################################################\n",
    "    # убираем ненужные для модели признаки. 'URL_TA' убрали, так как парсить я не умею\n",
    "    df_output.drop(['Restaurant_id', 'ID_TA', 'URL_TA'], axis=1, inplace=True)\n",
    "    df_output['Cuisine Style_NAN'] = df_output['Cuisine Style'].isna().astype(\n",
    "        'uint8')\n",
    "    df_output['Price Range_NAN'] = df_output['Price Range'].isna().astype('uint8')\n",
    "    \n",
    "    # Список кухонь\n",
    "    cities = df_output['City'].unique()\n",
    "    \n",
    "    # Словарь город:кол-во ресторанов\n",
    "    city_count = dict(df_output['City'].value_counts())\n",
    "    \n",
    "    # Словарь город:страна\n",
    "    country = {\n",
    "        'Paris': 'France',\n",
    "        'Hamburg': 'Germany',\n",
    "        'Rome': 'Italy',\n",
    "        'London': 'UK',\n",
    "        'Milan': 'Italy',\n",
    "        'Madrid': 'Spain',\n",
    "        'Oslo': 'Norway',\n",
    "        'Stockholm': 'Sweden',\n",
    "        'Krakow': 'Poland',\n",
    "        'Lyon': 'Paris',\n",
    "        'Lisbon': 'Portugal',\n",
    "        'Edinburgh': 'UK',\n",
    "        'Vienna': 'Austria',\n",
    "        'Warsaw': 'Poland',\n",
    "        'Amsterdam': 'Netherlands',\n",
    "        'Budapest': 'Hungary',\n",
    "        'Helsinki': 'Finland',\n",
    "        'Zurich': 'Switzerland',\n",
    "        'Luxembourg': 'Luxembourg',\n",
    "        'Berlin': 'Germany',\n",
    "        'Prague': 'Czechia',\n",
    "        'Munich': 'Germany',\n",
    "        'Bratislava': 'Slovakia',\n",
    "        'Brussels': 'Belgium',\n",
    "        'Ljubljana': 'Slovenia',\n",
    "        'Copenhagen': 'Denmark',\n",
    "        'Oporto': 'Portugal',\n",
    "        'Barcelona': 'Spain',\n",
    "        'Geneva': 'Switzerland',\n",
    "        'Athens': 'Greece',\n",
    "        'Dublin': 'Ireland'\n",
    "    }\n",
    "    # Список столиц\n",
    "\n",
    "    # ################### 2. NAN ##############################################################\n",
    "\n",
    "    df_output['Number of Reviews'].fillna(0, inplace=True)\n",
    "    df_output['Reviews'].fillna('[[], []]', inplace=True)\n",
    "    df_output['Cuisine Style'].fillna(\"['Other']\", inplace=True)\n",
    "    df_output['Cuisine Style'] = df_output['Cuisine Style'].apply(\n",
    "        lambda x: eval(x))\n",
    "\n",
    "    # Взорвали столбец \"Cuisine Style\"\n",
    "    exploded_cuisin_list = pd.Series.explode(\n",
    "        df_output['Cuisine Style']).value_counts()\n",
    "\n",
    "    # Список кухонь, количество встреч которых, мы наблюдаем реже чем медиальное значение общего количества встреч кухонь.\n",
    "    rare_cuisins_list = exploded_cuisin_list.loc[exploded_cuisin_list < round(\n",
    "        exploded_cuisin_list.median())].index.tolist()\n",
    "\n",
    "    # Список кухонь\n",
    "    cuisines = pd.Series.explode(df['Cuisine Style']).unique()\n",
    "\n",
    "    # Словарь ценового диапазона\n",
    "    price_dict = {'$': 1,\n",
    "                  '$$ - $$$': 2,\n",
    "                  '$$$$': 3}\n",
    "\n",
    "    # Заменяем строковые значения числовыми и заполняем пропуски наиболее часто встреяающимся значением\n",
    "    df_output['Price Range'] = df_output['Price Range'].map(price_dict)\n",
    "    df_output['Price Range'].fillna(2, inplace=True)\n",
    "\n",
    "    # ################### 3. Encoding ##############################################################\n",
    "\n",
    "    # City\n",
    "    dummies = df_output.City.str.get_dummies()\n",
    "    pd.concat([df_output, dummies], axis=1)\n",
    "\n",
    "    # Cuisins\n",
    "    for cus in cuisines:\n",
    "        df_output[cus] = df_output['Cuisine Style'].apply(fill_ones)\n",
    "    # ################### 4. Feature Engineering ####################################################\n",
    "\n",
    "    # Количество кухонь в ресторане\n",
    "    df_output['count_cuisines'] = df_output['Cuisine Style'].apply(\n",
    "        lambda x: len(x))\n",
    "\n",
    "    # Количество редких кухонь\n",
    "    df_output['rare_cuisines_count'] = df_output['Cuisine Style'].apply(\n",
    "        get_rare_cuisines_count)\n",
    "\n",
    "    # Бинарный признак редкости кухни\n",
    "    df_output['is_rare'] = df_output['Cuisine Style'].apply(is_rare)\n",
    "\n",
    "    # Количество ресторанов в городе\n",
    "    df_output['rest_count'] = df_output['City'].map(city_count)\n",
    "\n",
    "    # Количество людей в городе\n",
    "    df_output['population'] = df_output['City'].apply(\n",
    "        lambda x: get_population(x))\n",
    "\n",
    "    # Даты отзывов\n",
    "    df_output['date_review'] = df_output['Reviews'].apply(\n",
    "        lambda x: get_date(x))\n",
    "\n",
    "    # Дата первого отзыва по всем отзывам\n",
    "    min_date = pd.Series.explode(df_output['date_review']).min()\n",
    "\n",
    "    # Заполнение пустых значений датой первого отзыва\n",
    "    df_output['date_review'] = df_output['date_review'].apply(\n",
    "        lambda x: [min_date, min_date] if x == [] else x)\n",
    "\n",
    "    # Берем первый элемент из списка дат в каждой строке, так как он соответствует более позднему комментарию\n",
    "    df_output['last_review_date'] = df_output['date_review'].apply(\n",
    "        lambda x: x[0])\n",
    "\n",
    "    # Берем первый элемент из списка дат в каждой строке, если количество дат отзывов меньше двух.\n",
    "    # Иначе- второй,так как может быть 3 даты отзывов\n",
    "    df_output['prelast_review_date'] = df_output['date_review'].apply(\n",
    "        lambda x: x[0] if len(x) < 2 else x[1])\n",
    "\n",
    "    # Признак количества дней между последними отзывами\n",
    "    df_output['delta_date'] = df_output['date_review'].apply(\n",
    "        lambda x: get_delta_date(x))\n",
    "\n",
    "    # Признак количества дней между последним отзывом и сегодняшней датой\n",
    "    today = datetime.now()\n",
    "    df_output['delta_current_date'] = df_output['last_review_date'].apply(\n",
    "        lambda x: (today - x).days)\n",
    "        \n",
    "    #  Признак полярности отзыва\n",
    "    df_output['polarity_rev'] = df_output.Reviews.apply(lambda x: polarity_rev(x))\n",
    "    df_output['polarity_rev'] = df_output['polarity_rev'].fillna(df_output.polarity_rev.mean())\n",
    "    # ################### 5. Clean ####################################################\n",
    "    # убираем признаки которые еще не успели обработать,\n",
    "    # модель на признаках с dtypes \"object\" обучаться не будет, просто выберим их и удалим\n",
    "    object_columns = [\n",
    "        s for s in df_output.columns if df_output[s].dtypes == 'object']\n",
    "    df_output.drop(object_columns, axis=1, inplace=True)\n",
    "\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">По хорошему, можно было бы перевести эту большую функцию в класс и разбить на подфункции (согласно ООП). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Запускаем и проверяем что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc = preproc_data(data)\n",
    "df_preproc.drop(['last_review_date','prelast_review_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15,10)\n",
    "sns.heatmap(df_preproc.corr(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь выделим тестовую часть\n",
    "train_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\n",
    "test_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n",
    "\n",
    "y = train_data.Rating.values            # наш таргет\n",
    "X = train_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \n",
    "Это поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n",
    "# выделим 20% данных на валидацию (параметр test_size)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем\n",
    "test_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model \n",
    "Сам ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки:\n",
    "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
    "from sklearn import metrics # инструменты для оценки точности модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\n",
    "model = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель на тестовом наборе данных\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Видим разницу в том, что реальные рейтинги всегда кратны 0.5\n",
    "# Напишем функцию соответствующей корректировки предсказанных рейтингов\n",
    "def fine_rating_pred(rating_pred):\n",
    "    if rating_pred <= 0.5:\n",
    "        return 0.0\n",
    "    if rating_pred <= 1.5:\n",
    "        return 1.0\n",
    "    if rating_pred <= 1.75:\n",
    "        return 1.5\n",
    "    if rating_pred <= 2.25:\n",
    "        return 2.0\n",
    "    if rating_pred <= 2.75:\n",
    "        return 2.5\n",
    "    if rating_pred <= 3.25:\n",
    "        return 3.0\n",
    "    if rating_pred <= 3.75:\n",
    "        return 3.5\n",
    "    if rating_pred <= 4.25:\n",
    "        return 4.0\n",
    "    if rating_pred <= 4.75:\n",
    "        return 4.5\n",
    "    return 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применим такое округление\n",
    "for i in range(len(y_pred)):\n",
    "    y_pred[i] = fine_rating_pred(y_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n",
    "# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre 0.1731875\n",
    "# best 0.1731875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\n",
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(15).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "Если все устраевает - готовим Submission на кагл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применим округление\n",
    "for i in range(len(predict_submission)):\n",
    "    predict_submission[i] = fine_rating_pred(predict_submission[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['Rating'] = predict_submission\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's next?\n",
    "Или что делать, чтоб улучшить результат:\n",
    "* Обработать оставшиеся признаки в понятный для машины формат\n",
    "* Посмотреть, что еще можно извлечь из признаков\n",
    "* Сгенерировать новые признаки\n",
    "* Подгрузить дополнительные данные, например: по населению или благосостоянию городов\n",
    "* Подобрать состав признаков\n",
    "\n",
    "В общем, процесс творческий и весьма увлекательный! Удачи в соревновании!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
